{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fan_tumor_detect.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abx67/ADS_Teaching/blob/master/fan_tumor_detect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wrgl42gH4Mgh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook is used to localize tumor area for `tumor_091.tif`.  "
      ]
    },
    {
      "metadata": {
        "id": "K9aBDiAkL5JM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Done(12.19)----------> Improvement:\n",
        "1. `kp_image.img_to_array()` preprocess images more efficiently. \n",
        "2. `np.asarray()` would not copy array like `np.array()`.\n",
        "3. `model`: VGG16+global pooling 2D instead of flatten layer. \n",
        "4. `label2mask`: change i with j because width and height issue.\n",
        "\n",
        "---\n",
        "\n",
        "TODO(12.19):\n",
        "1. **find tissue areas improvement**. (do not use too many non-tissue areas so as to improve performance.)\n",
        "2. Evaluation: check accuracy! \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GQvI12OK6-tP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xydGWdKs6bJ5",
        "colab_type": "code",
        "outputId": "1946d04d-e9e9-484e-c048-256f85f8baab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "# Install the OpenSlide C library and Python bindings\n",
        "!apt-get install openslide-tools\n",
        "!pip install openslide-python"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "openslide-tools is already the newest version (3.4.1+dfsg-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n",
            "Requirement already satisfied: openslide-python in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from openslide-python) (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->openslide-python) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9xLCkPxn6jzB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from openslide import open_slide, __library_version__ as openslide_version\n",
        "import os\n",
        "from PIL import Image\n",
        "from skimage.color import rgb2gray\n",
        "from tensorflow.python.keras.preprocessing import image as kp_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TDXPa2Qs6Vyg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 0: Download Slide and Show Details"
      ]
    },
    {
      "metadata": {
        "id": "c4Q1jV2F7aC5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "slide_path = 'tumor_091.tif'\n",
        "tumor_mask_path = 'tumor_091_mask.tif'\n",
        "\n",
        "slide_url = 'https://storage.googleapis.com/applied-dl/%s' % slide_path\n",
        "mask_url = 'https://storage.googleapis.com/applied-dl/%s' % tumor_mask_path\n",
        "\n",
        "# Download the whole slide image\n",
        "if not os.path.exists(slide_path):\n",
        "  !curl -O $slide_url\n",
        "\n",
        "# Download the tumor mask\n",
        "if not os.path.exists(tumor_mask_path):\n",
        "  !curl -O $mask_url"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mIxvb2Md-YXe",
        "colab_type": "code",
        "outputId": "70bc2e0b-14de-4807-ad36-c8028b4f35d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "slide = open_slide(slide_path)\n",
        "print (\"Read WSI from %s with width: %d, height: %d\" % (slide_path, \n",
        "                                                        slide.level_dimensions[0][0], \n",
        "                                                        slide.level_dimensions[0][1]))\n",
        "\n",
        "tumor_mask = open_slide(tumor_mask_path)\n",
        "print (\"Read tumor mask from %s\" % (tumor_mask_path))\n",
        "\n",
        "print(\"Slide includes %d levels\", len(slide.level_dimensions))\n",
        "for i in range(len(slide.level_dimensions)):\n",
        "    print(\"Level %d, dimensions: %s downsample factor %d\" % (i, \n",
        "                                                             slide.level_dimensions[i], \n",
        "                                                             slide.level_downsamples[i]))\n",
        "    assert tumor_mask.level_dimensions[i][0] == slide.level_dimensions[i][0]\n",
        "    assert tumor_mask.level_dimensions[i][1] == slide.level_dimensions[i][1]\n",
        "\n",
        "# Verify downsampling works as expected\n",
        "width, height = slide.level_dimensions[7]\n",
        "assert width * slide.level_downsamples[7] == slide.level_dimensions[0][0]\n",
        "assert height * slide.level_downsamples[7] == slide.level_dimensions[0][1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read WSI from tumor_091.tif with width: 61440, height: 53760\n",
            "Read tumor mask from tumor_091_mask.tif\n",
            "Slide includes %d levels 8\n",
            "Level 0, dimensions: (61440, 53760) downsample factor 1\n",
            "Level 1, dimensions: (30720, 26880) downsample factor 2\n",
            "Level 2, dimensions: (15360, 13440) downsample factor 4\n",
            "Level 3, dimensions: (7680, 6720) downsample factor 8\n",
            "Level 4, dimensions: (3840, 3360) downsample factor 16\n",
            "Level 5, dimensions: (1920, 1680) downsample factor 32\n",
            "Level 6, dimensions: (960, 840) downsample factor 64\n",
            "Level 7, dimensions: (480, 420) downsample factor 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6xY4OamaNH7o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 1: Read Slide and Preprocess Data"
      ]
    },
    {
      "metadata": {
        "id": "HPgd2tKB-xfW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_slide(slide, x, y, level, width, height, as_float=False):\n",
        "    im = slide.read_region((x,y), level, (width, height))\n",
        "    im = im.convert('RGB') # drop the alpha channel\n",
        "    return im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "weIvOKHke5uU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_aug(x):\n",
        "  \n",
        "  #rotate 4 directions and left-right flip\n",
        "  x1 = np.rot90(x,k=1)\n",
        "  x2 = np.rot90(x1,k=1)\n",
        "  x3 = np.rot90(x2,k=1)\n",
        "  x4 = np.rot90(x3,k=1)\n",
        "  x5 = x1[:, ::-1]\n",
        "  x6 = x2[:,::-1]\n",
        "  x7 = x3[:,::-1]\n",
        "  x8 = x4[:,::-1]\n",
        "  x_new= [x1,x2,x3,x4,x5,x6,x7,x8]\n",
        "  \n",
        "  return x_new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EHmhAVIJuOlc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # Version 1.0: save images to disk\n",
        "# def data_preprocess(slide, tumor_mask, level, window_size=(299,299),\n",
        "#                            center_size=(128,128),stride=128):\n",
        "  \n",
        "#   if not os.path.exists('train'): \n",
        "#     os.mkdir('train')\n",
        "#   if not os.path.exists('train/tumor'): \n",
        "#     os.mkdir('train/tumor')\n",
        "#   if not os.path.exists('train/normal'):\n",
        "#     os.mkdir('train/normal')\n",
        "  \n",
        "#   factor = int(slide.level_downsamples[level])\n",
        "#   tumor_count = 1\n",
        "#   normal_count = 1\n",
        "#   x_step = (window_size[0]-center_size[0])//2\n",
        "#   y_step = (window_size[1]-center_size[1])//2\n",
        "#   imgs0 = []\n",
        "#   imgs1 = []\n",
        "  \n",
        "#   for i in range(0, slide.level_dimensions[level][0]-window_size[0], stride):  #width\n",
        "#     for j in range(0, slide.level_dimensions[level][1]-window_size[1], stride):   #height\n",
        "#       slide_img = read_slide(slide, i*factor, j*factor, level, window_size[0], window_size[1], as_float=False)\n",
        "#       mask_img = read_slide(tumor_mask, (i+x_step)*factor, (j+y_step)*factor, level, center_size[0], center_size[1], as_float=False)\n",
        "#       if np.sum(mask_img)==0:   #normal\n",
        "#         #slide_img.save(\"train/normal/%d.jpg\" % normal_count)\n",
        "#         #normal_count += 1\n",
        "#         if np.random.uniform(size=1)>0.6:\n",
        "#           imgs0.append(kp_image.img_to_array(slide_img)/255)   #np.asarray?\n",
        "#           #labels.append(0.)\n",
        "#       elif np.sum(mask_img)!=0: #tumor\n",
        "#         slide_img.save(\"train/tumor/%d.jpg\" % tumor_count)\n",
        "#         tumor_count += 1\n",
        "#         imgs1 += data_aug(kp_image.img_to_array(slide_img)/255)\n",
        "        \n",
        "#   imgs = np.concatenate((np.asarray(imgs0),np.asarray(imgs1)))\n",
        "#   labels = np.append(np.repeat(0.,len(imgs0)),np.repeat(1.,len(imgs1)))\n",
        "#   ind = [i for i in range(labels.shape[0])]\n",
        "#   np.random.shuffle(ind)\n",
        "  \n",
        "#   return imgs[ind], labels[ind]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rq4sZ04E0bx_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Version 2.0\n",
        "def data_preprocess(slide, tumor_mask, level, window_size=(299,299),\n",
        "                           center_size=(128,128),stride=128):\n",
        "  \n",
        "  factor = int(slide.level_downsamples[level])\n",
        "  tumor_count = 1\n",
        "  normal_count = 1\n",
        "  x_step = (window_size[0]-center_size[0])//2\n",
        "  y_step = (window_size[1]-center_size[1])//2\n",
        "  imgs0 = []\n",
        "  imgs1 = []\n",
        "  \n",
        "  for i in range(0, slide.level_dimensions[level][0]-window_size[0], stride):  \n",
        "    for j in range(0, slide.level_dimensions[level][1]-window_size[1], stride): \n",
        "      slide_img = read_slide(slide, i*factor, j*factor, level, window_size[0], window_size[1], as_float=False)\n",
        "      mask_img = read_slide(tumor_mask, (i+x_step)*factor, (j+y_step)*factor, level, center_size[0], center_size[1], as_float=False)\n",
        "      if np.sum(mask_img)==0:   #normal\n",
        "        if np.random.uniform(size=1)>0.75: #0.75 has to be tuned each time when we change the size!\n",
        "          imgs0.append(kp_image.img_to_array(slide_img)/255)  \n",
        "      elif np.sum(mask_img)!=0: #tumor\n",
        "        imgs1 += data_aug(kp_image.img_to_array(slide_img)/255)\n",
        "        \n",
        "  imgs = np.concatenate((np.asarray(imgs0),np.asarray(imgs1)))\n",
        "  labels = np.append(np.repeat(0.,len(imgs0)),np.repeat(1.,len(imgs1)))\n",
        "  ind = [i for i in range(labels.shape[0])]\n",
        "  np.random.shuffle(ind)\n",
        "  \n",
        "  return imgs[ind], labels[ind]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "io0P6kIBdGEZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "window_size=(80,80)\n",
        "center_size=(50,50)\n",
        "stride=50\n",
        "level=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cs0wlqBgFAyx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "patches, labels= data_preprocess(slide, tumor_mask, level=3, window_size=window_size,\n",
        "                           center_size=center_size,stride=stride)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rtojwj50m3yc",
        "colab_type": "code",
        "outputId": "c761638e-7b2b-4dad-9912-e945874ecb84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "np.unique(labels,return_counts=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0., 1.]), array([4898, 3376]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "8QehlpGUNttn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 2: Train a Model"
      ]
    },
    {
      "metadata": {
        "id": "1cJRI1Y7PGMh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.applications.VGG16(input_shape=(299, 299, 3),include_top=False)\n",
        "model.trainable = False\n",
        "x = model.output\n",
        "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "predictions = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_baseline = tf.keras.models.Model(inputs = model.input, outputs = predictions)\n",
        "model_baseline.compile(loss =\"binary_crossentropy\",\n",
        "                       optimizer = tf.train.RMSPropOptimizer(learning_rate=0.0001),\n",
        "                       metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v5xYVQkZZkWn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model_baseline.fit(patches,labels,epochs=10,batch_size=32,validation_split=0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ig3rkDwv1eXl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model_baseline.save_weights('baseline_80_50.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XVOvQcZzKYaZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # if running time died, please run this step after building model directly.\n",
        "# model_baseline.load_weights('baseline_80_50.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m2XBf7uBdEvw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 2.1 weighted loss"
      ]
    },
    {
      "metadata": {
        "id": "kJ2yp-oQdBAK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from functools import partial, update_wrapper\n",
        "\n",
        "def wrapped_partial(func, *args, **kwargs):\n",
        "\tpartial_func = partial(func, *args, **kwargs)\n",
        "\tupdate_wrapper(partial_func, func)\n",
        "\treturn partial_func\n",
        "\n",
        "def binary_crossentropy_weigted(y_true, y_pred, class_weights):\n",
        "\ty_pred = K.clip(y_pred, K.epsilon(), 1.0 - K.epsilon())\n",
        "\tloss = K.mean(class_weights*(-y_true * K.log(y_pred) - (1.0 - y_true) * K.log(1.0 - y_pred)),axis=-1)\n",
        "\treturn loss\n",
        "\n",
        "custom_loss = wrapped_partial(binary_crossentropy_weigted, class_weights=np.array([1.0, 2.0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lyJz2c8Bd7R0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 2.2 multi-scale"
      ]
    },
    {
      "metadata": {
        "id": "UdjPJK5Td69s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### layers defination\n",
        "\n",
        "input_shape_high = (150, 150, 3)\n",
        "input_shape_low = (75, 75, 3)\n",
        "\n",
        "\n",
        "## scale 1\n",
        "# input4 = tf.keras.layers.Input(shape = input_shape_high)\n",
        "model4 = tf.keras.applications.VGG16(input_shape=input_shape_high,include_top=False)\n",
        "model4.trainable = False\n",
        "input4 = model4.output\n",
        "layer_level4_1 = tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape_high,\n",
        "                 padding='same')(input4)\n",
        "layer_level4_2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(layer_level4_1)\n",
        "layer_level4_3 = tf.keras.layers.Conv2D(64, kernel_size=(3, 3),\n",
        "                                      activation='relu',\n",
        "                                      padding='same')(layer_level4_2)\n",
        "predictions4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(layer_level4_3)\n",
        "# predictions4 = tf.keras.layers.Dense(1, activation=\"sigmoid\")(layer_level4)\n",
        "\n",
        "## scale 2\n",
        "# input5 = tf.keras.layers.Input(shape = input_shape_low)\n",
        "model5 = tf.keras.applications.InceptionV3(input_shape=input_shape_low,include_top=False)\n",
        "model5.trainable = False\n",
        "input5 = model5.output\n",
        "layer_level5_1 = tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation = 'relu',\n",
        "                 input_shape = input_shape_low,\n",
        "                 padding = 'same')(input5)\n",
        "layer_level5_2 = tf.keras.layers.MaxPooling2D(pool_size = (2, 2))(layer_level5_1)\n",
        "predictions5 = tf.keras.layers.Conv2D(64, kernel_size = (3, 3),\n",
        "                                      activation = 'relu',\n",
        "                                      padding = 'same')(layer_level5_2)\n",
        "# predictions5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(layer_level5_3)\n",
        "\n",
        "## multi-scale\n",
        "added = tf.keras.layers.Add()([predictions4, predictions5])\n",
        "# added = tf.keras.layers.concatenate([predictions4, predictions5])\n",
        "# merged = Dense(1024, activation='relu')(merged)\n",
        "# merged = Dense(num_classes, activation='softmax')(merged)\n",
        "\n",
        "combine_layer_1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(added)\n",
        "# combine_layer = tf.keras.layers.Flatten()(combine_layer)\n",
        "combine_layer_2 = tf.keras.layers.Dense(128, activation ='relu')(combine_layer_1)\n",
        "out = tf.keras.layers.Dense(1, activation='sigmoid')(combine_layer_2)\n",
        "\n",
        "combine_model = tf.keras.models.Model(inputs=[model4.input, model5.input], outputs=out)\n",
        "\n",
        "combine_model.compile(optimizer=tf.train.RMSPropOptimizer(learning_rate=0.001),\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OUJlTm9BbSyG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "patches_3, labels_3 = data_preprocess(slide, tumor_mask, level=3, window_size=(150,150),\n",
        "                           center_size=(100,100),stride=stride)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qcJvsOnYbTa8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "patches_4, labels_4 = data_preprocess(slide, tumor_mask, level=4, window_size=(75,75),\n",
        "                           center_size=(50,50),stride=stride)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9xb6tFd6atw2",
        "colab_type": "code",
        "outputId": "9e9b7f41-6303-46ed-ad57-af165fb09131",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        }
      },
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "batch_size=10\n",
        "\n",
        "combine_model.fit([patches_3,patches_4],labels_3,\n",
        "                  batch_size=batch_size,epochs=epochs,validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-622abd4cac80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m combine_model.fit([patches_3,patches_4],labels_3,\n\u001b[0;32m----> 5\u001b[0;31m                   batch_size=batch_size,epochs=epochs,validation_split=0.2)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps_per_epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1536\u001b[0;31m         validation_split=validation_split)\n\u001b[0m\u001b[1;32m   1537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     x, y, sample_weights = self._standardize_weights(x, y, sample_weight,\n\u001b[0;32m--> 992\u001b[0;31m                                                      class_weight, batch_size)\n\u001b[0m\u001b[1;32m    993\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_weights\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   1167\u001b[0m       \u001b[0;31m# Check that all arrays have the same length.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m         \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_array_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m           \u001b[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_array_lengths\u001b[0;34m(inputs, targets, weights)\u001b[0m\n\u001b[1;32m    415\u001b[0m     raise ValueError('All input arrays (x) should have '\n\u001b[1;32m    416\u001b[0m                      \u001b[0;34m'the same number of samples. Got array shapes: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m                      str([x.shape for x in inputs]))\n\u001b[0m\u001b[1;32m    418\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     raise ValueError('All target arrays (y) should have '\n",
            "\u001b[0;31mValueError\u001b[0m: All input arrays (x) should have the same number of samples. Got array shapes: [(9242, 150, 150, 3), (2222, 75, 75, 3)]"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "B_dNnKnfN9gD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 3: Prediction for Trained Slide"
      ]
    },
    {
      "metadata": {
        "id": "2WTwD_8MfbyB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## convert labels to mask\n",
        "def label2mask(y_pred, mask_size, window_size=(150,150),center_size=(100,100),stride=100):\n",
        "  \n",
        "  mask_pred=np.zeros((mask_size[1],mask_size[0]))\n",
        "  count=0\n",
        "  x_grid=center_size[0]//2\n",
        "  y_grid=center_size[1]//2\n",
        "  for j in range(0,mask_size[0]-window_size[0],stride):    \n",
        "    for i in range(0,mask_size[1]-window_size[1],stride):  \n",
        "      x_pos=i+window_size[0]//2\n",
        "      y_pos=j+window_size[1]//2\n",
        "      if count >= len(y_pred):\n",
        "        count -= 1\n",
        "      mask_pred[(x_pos-x_grid):(x_pos+x_grid),(y_pos-y_grid):(y_pos+y_grid)]=y_pred[count]\n",
        "      count += 1\n",
        "  return(mask_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OI8ET1RhyoQl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Note: we should get all labels of slide rather than the center region here! \n",
        "# Otherwise, we would underestimate our evaluation.\n",
        "def get_test_pred(model, slide, level, window_size=(299,299),\n",
        "                     center_size=(128,128),stride=128):\n",
        "  \n",
        "  factor = int(slide.level_downsamples[level])\n",
        "  preds = []\n",
        "  for i in range(0, slide.level_dimensions[level][0]-window_size[0],stride):  \n",
        "    for j in range(0, slide.level_dimensions[level][1]-window_size[1],stride): \n",
        "      slide_img = read_slide(slide, i*factor, j*factor, level, window_size[0], window_size[1], as_float=False)\n",
        "      patches = kp_image.img_to_array(slide_img)/255\n",
        "      y_pred = model.predict(np.expand_dims(patches.astype('float32'),axis=0))\n",
        "      preds.append(y_pred)\n",
        "  \n",
        "  mask_pred = label2mask(np.asarray(preds), slide.level_dimensions[level], window_size = window_size, \n",
        "                         center_size=center_size, stride = stride)\n",
        "  return mask_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9L0QrIgEftuO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mask_pred = get_test_pred(model_baseline, slide, level, window_size=window_size,\n",
        "                          center_size=center_size,stride=stride)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s2YQqLV8KWU5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "slide_image = np.asarray(read_slide(slide, x=0, y=0, \n",
        "                         level=level, \n",
        "                         width=slide.level_dimensions[level][0], \n",
        "                         height=slide.level_dimensions[level][1]))\n",
        "mask_image = np.asarray(read_slide(tumor_mask, x=0, y=0, \n",
        "                        level=level, \n",
        "                        width=slide.level_dimensions[level][0], \n",
        "                        height=slide.level_dimensions[level][1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d8oywC7H24vc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plt.figure(figsize=(10,10), dpi=50)\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.subplot(2,2,1)\n",
        "plt.imshow(slide_image)\n",
        "plt.imshow(mask_image[:,:,0],cmap='jet', alpha=0.5)\n",
        "plt.grid(False)\n",
        "plt.subplot(2,2,2)\n",
        "plt.imshow(slide_image)\n",
        "plt.imshow(mask_pred, cmap='jet',alpha=0.5) # Red regions contains cancer.\n",
        "plt.grid(False)\n",
        "plt.subplot(2,2,3)\n",
        "plt.imshow(mask_image[:,:,0])\n",
        "plt.imshow(mask_pred, cmap='jet',alpha=0.5) # Red regions contains cancer.\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q4gCF8yyyZ38",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 4: Prediction for a New Slide"
      ]
    },
    {
      "metadata": {
        "id": "t4ALhWIbys__",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Download a test slide\n",
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "fname = 'tumor_078.tif'\n",
        "if not os.path.exists(fname): \n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  f_ = drive.CreateFile({'id': '1cAFgPCkGR0zH0gqCDo4yBnstNoZmjp3C'})\n",
        "  f_.GetContentFile(fname)\n",
        "  fname = 'tumor_078_mask.tif'\n",
        "  f_ = drive.CreateFile({'id': '1ZC2urznY3gRebUG3PN2BtYD1ZPZ7GPYq'})\n",
        "  f_.GetContentFile(fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V4Da20maykkd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "slide_test_path = 'tumor_078.tif'\n",
        "test_mask_path = 'tumor_078_mask.tif'\n",
        "slide_test = open_slide(slide_test_path)\n",
        "mask_test = open_slide(test_mask_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JAN2ROv-zO5E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mask_pred_test = get_test_pred(model_baseline, slide_test, level, window_size=window_size,\n",
        "                               center_size=center_size,stride=stride)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JZKJJ6lZzfLU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "slide_test_image = np.asarray(read_slide(slide_test, x=0, y=0, \n",
        "                              level=level, \n",
        "                              width=slide_test.level_dimensions[level][0], \n",
        "                              height=slide_test.level_dimensions[level][1]))\n",
        "mask_test_image = np.asarray(read_slide(mask_test, x=0, y=0, \n",
        "                             level=level, \n",
        "                             width=slide_test.level_dimensions[level][0], \n",
        "                             height=slide_test.level_dimensions[level][1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J3OOZ0i6zZM4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plt.figure(figsize=(10,10), dpi=50)\n",
        "plt.figure(figsize=(12,10))\n",
        "plt.subplot(2,2,1)\n",
        "plt.imshow(slide_test_image)\n",
        "plt.imshow(mask_test_image[:,:,0],cmap='jet', alpha=0.5)\n",
        "plt.grid(False)\n",
        "plt.subplot(2,2,2)\n",
        "plt.imshow(slide_test_image)\n",
        "plt.imshow(mask_pred_test, cmap='jet',alpha=0.5) # Red regions contains cancer.\n",
        "plt.grid(False)\n",
        "plt.subplot(2,2,3)\n",
        "plt.imshow(mask_test_image[:,:,0])\n",
        "plt.imshow(mask_pred_test, cmap='jet',alpha=0.5) # Red regions contains cancer.\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OhLnlTSsOMFn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 5: Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "Wpd0yDqKCD3d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "import sklearn\n",
        "\n",
        "fpr, tpr, thresholds = metrics.roc_curve(mask_test_image[:,:,0].reshape(-1).astype('float32'), \n",
        "                                         mask_pred_test.reshape(-1), pos_label=None)\n",
        "\n",
        "print('AUC:%s'%(metrics.auc(fpr, tpr)))\n",
        "\n",
        "plt.title('ROC curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.plot(fpr, tpr)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7OTmcRX5PfTv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "thres = thresholds[np.argmax(1-fpr+tpr)]\n",
        "mask_pred_test_labels = np.zeros(mask_pred_test.shape)\n",
        "mask_pred_test_labels[mask_pred_test > thres] = 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G7q2Ns5cPWRc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "mat = confusion_matrix(mask_test_image[:,:,0].reshape(-1).astype('uint8'), \n",
        "                       mask_pred_test_labels.reshape(-1).astype('uint8'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "01DkXjifraYv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j5heh1T5pU4s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "recall = mat[1][1]/(mat[1][1]+mat[1][0])   #tp/tp+fn\n",
        "precision = mat[1][1]/(mat[1][1]+mat[0][1])  #tp/tp+fp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OAR8jE4ojEnQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Recall:{}'.format(recall))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FlOsPbrxjIu2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Precision:{}'.format(precision))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}