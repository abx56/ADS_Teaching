{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fan_tumor_detect.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abx67/ADS_Teaching/blob/master/fan_tumor_detect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wrgl42gH4Mgh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook is used to localize tumor area for `tumor_091.tif`.  "
      ]
    },
    {
      "metadata": {
        "id": "K9aBDiAkL5JM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Done(12.19)----------> Improvement:\n",
        "1. `kp_image.img_to_array()` preprocess images more efficiently. \n",
        "2. `np.asarray()` would not copy array like `np.array()`.\n",
        "3. `model`: VGG16+global pooling 2D instead of flatten layer. \n",
        "4. `label2mask`: change i with j because width and height issue.\n",
        "\n",
        "---\n",
        "\n",
        "TODO(12.19):\n",
        "1. **find tissue areas improvement**. (do not use too many non-tissue areas so as to improve performance.)\n",
        "2. Evaluation: check accuracy! \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GQvI12OK6-tP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xydGWdKs6bJ5",
        "colab_type": "code",
        "outputId": "e46d88de-58b6-4948-81b1-8e6f7e27ec1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "cell_type": "code",
      "source": [
        "# Install the OpenSlide C library and Python bindings\n",
        "!apt-get install openslide-tools\n",
        "!pip install openslide-python"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libopenslide0\n",
            "Suggested packages:\n",
            "  libtiff-tools\n",
            "The following NEW packages will be installed:\n",
            "  libopenslide0 openslide-tools\n",
            "0 upgraded, 2 newly installed, 0 to remove and 8 not upgraded.\n",
            "Need to get 92.5 kB of archives.\n",
            "After this operation, 268 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenslide0 amd64 3.4.1+dfsg-2 [79.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 openslide-tools amd64 3.4.1+dfsg-2 [12.7 kB]\n",
            "Fetched 92.5 kB in 1s (110 kB/s)\n",
            "Selecting previously unselected package libopenslide0.\n",
            "(Reading database ... 110842 files and directories currently installed.)\n",
            "Preparing to unpack .../libopenslide0_3.4.1+dfsg-2_amd64.deb ...\n",
            "Unpacking libopenslide0 (3.4.1+dfsg-2) ...\n",
            "Selecting previously unselected package openslide-tools.\n",
            "Preparing to unpack .../openslide-tools_3.4.1+dfsg-2_amd64.deb ...\n",
            "Unpacking openslide-tools (3.4.1+dfsg-2) ...\n",
            "Setting up libopenslide0 (3.4.1+dfsg-2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up openslide-tools (3.4.1+dfsg-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting openslide-python\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/5a/5b0adeabce81f018a9e4ffe9a419536064bc95c1b12194aff9b7e48f91f7/openslide-python-1.1.1.tar.gz (312kB)\n",
            "\u001b[K    100% |████████████████████████████████| 317kB 22.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from openslide-python) (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->openslide-python) (0.46)\n",
            "Building wheels for collected packages: openslide-python\n",
            "  Running setup.py bdist_wheel for openslide-python ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/56/44/7e/16c9fc72cfbf1bffe48676b6835843d21abcc56566e958e7d6\n",
            "Successfully built openslide-python\n",
            "Installing collected packages: openslide-python\n",
            "Successfully installed openslide-python-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9xLCkPxn6jzB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from openslide import open_slide, __library_version__ as openslide_version\n",
        "import os\n",
        "from PIL import Image\n",
        "from skimage.color import rgb2gray\n",
        "from tensorflow.python.keras.preprocessing import image as kp_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TDXPa2Qs6Vyg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 0: Download Slide and Show Details"
      ]
    },
    {
      "metadata": {
        "id": "c4Q1jV2F7aC5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "dd553590-5730-4c73-902f-e886b0c97892"
      },
      "cell_type": "code",
      "source": [
        "slide_path = 'tumor_091.tif'\n",
        "tumor_mask_path = 'tumor_091_mask.tif'\n",
        "\n",
        "slide_url = 'https://storage.googleapis.com/applied-dl/%s' % slide_path\n",
        "mask_url = 'https://storage.googleapis.com/applied-dl/%s' % tumor_mask_path\n",
        "\n",
        "# Download the whole slide image\n",
        "if not os.path.exists(slide_path):\n",
        "  !curl -O $slide_url\n",
        "\n",
        "# Download the tumor mask\n",
        "if not os.path.exists(tumor_mask_path):\n",
        "  !curl -O $mask_url"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  521M  100  521M    0     0   141M      0  0:00:03  0:00:03 --:--:--  141M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 14.6M  100 14.6M    0     0  45.5M      0 --:--:-- --:--:-- --:--:-- 45.6M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mIxvb2Md-YXe",
        "colab_type": "code",
        "outputId": "0d129eb9-3661-4e4c-ace7-3cd40f602630",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "slide = open_slide(slide_path)\n",
        "print (\"Read WSI from %s with width: %d, height: %d\" % (slide_path, \n",
        "                                                        slide.level_dimensions[0][0], \n",
        "                                                        slide.level_dimensions[0][1]))\n",
        "\n",
        "tumor_mask = open_slide(tumor_mask_path)\n",
        "print (\"Read tumor mask from %s\" % (tumor_mask_path))\n",
        "\n",
        "print(\"Slide includes %d levels\", len(slide.level_dimensions))\n",
        "for i in range(len(slide.level_dimensions)):\n",
        "    print(\"Level %d, dimensions: %s downsample factor %d\" % (i, \n",
        "                                                             slide.level_dimensions[i], \n",
        "                                                             slide.level_downsamples[i]))\n",
        "    assert tumor_mask.level_dimensions[i][0] == slide.level_dimensions[i][0]\n",
        "    assert tumor_mask.level_dimensions[i][1] == slide.level_dimensions[i][1]\n",
        "\n",
        "# Verify downsampling works as expected\n",
        "width, height = slide.level_dimensions[7]\n",
        "assert width * slide.level_downsamples[7] == slide.level_dimensions[0][0]\n",
        "assert height * slide.level_downsamples[7] == slide.level_dimensions[0][1]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read WSI from tumor_091.tif with width: 61440, height: 53760\n",
            "Read tumor mask from tumor_091_mask.tif\n",
            "Slide includes %d levels 8\n",
            "Level 0, dimensions: (61440, 53760) downsample factor 1\n",
            "Level 1, dimensions: (30720, 26880) downsample factor 2\n",
            "Level 2, dimensions: (15360, 13440) downsample factor 4\n",
            "Level 3, dimensions: (7680, 6720) downsample factor 8\n",
            "Level 4, dimensions: (3840, 3360) downsample factor 16\n",
            "Level 5, dimensions: (1920, 1680) downsample factor 32\n",
            "Level 6, dimensions: (960, 840) downsample factor 64\n",
            "Level 7, dimensions: (480, 420) downsample factor 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6xY4OamaNH7o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 1: Read Slide and Preprocess Data"
      ]
    },
    {
      "metadata": {
        "id": "HPgd2tKB-xfW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_slide(slide, x, y, level, width, height, as_float=False):\n",
        "    im = slide.read_region((x,y), level, (width, height))\n",
        "    im = im.convert('RGB') # drop the alpha channel\n",
        "    return im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "weIvOKHke5uU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_aug(x):\n",
        "  \n",
        "  #rotate 4 directions and left-right flip\n",
        "  x1 = np.rot90(x,k=1)\n",
        "  x2 = np.rot90(x1,k=1)\n",
        "  x3 = np.rot90(x2,k=1)\n",
        "  x4 = np.rot90(x3,k=1)\n",
        "  x5 = x1[:, ::-1]\n",
        "  x6 = x2[:,::-1]\n",
        "  x7 = x3[:,::-1]\n",
        "  x8 = x4[:,::-1]\n",
        "  x_new= [x1,x2,x3,x4,x5,x6,x7,x8]\n",
        "  \n",
        "  return x_new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EHmhAVIJuOlc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # Version 1.0: save images to disk\n",
        "# def data_preprocess(slide, tumor_mask, level, window_size=(299,299),\n",
        "#                            center_size=(128,128),stride=128):\n",
        "  \n",
        "#   if not os.path.exists('train'): \n",
        "#     os.mkdir('train')\n",
        "#   if not os.path.exists('train/tumor'): \n",
        "#     os.mkdir('train/tumor')\n",
        "#   if not os.path.exists('train/normal'):\n",
        "#     os.mkdir('train/normal')\n",
        "  \n",
        "#   factor = int(slide.level_downsamples[level])\n",
        "#   tumor_count = 1\n",
        "#   normal_count = 1\n",
        "#   x_step = (window_size[0]-center_size[0])//2\n",
        "#   y_step = (window_size[1]-center_size[1])//2\n",
        "#   imgs0 = []\n",
        "#   imgs1 = []\n",
        "  \n",
        "#   for i in range(0, slide.level_dimensions[level][0]-window_size[0], stride):  #width\n",
        "#     for j in range(0, slide.level_dimensions[level][1]-window_size[1], stride):   #height\n",
        "#       slide_img = read_slide(slide, i*factor, j*factor, level, window_size[0], window_size[1], as_float=False)\n",
        "#       mask_img = read_slide(tumor_mask, (i+x_step)*factor, (j+y_step)*factor, level, center_size[0], center_size[1], as_float=False)\n",
        "#       if np.sum(mask_img)==0:   #normal\n",
        "#         #slide_img.save(\"train/normal/%d.jpg\" % normal_count)\n",
        "#         #normal_count += 1\n",
        "#         if np.random.uniform(size=1)>0.6:\n",
        "#           imgs0.append(kp_image.img_to_array(slide_img)/255)   #np.asarray?\n",
        "#           #labels.append(0.)\n",
        "#       elif np.sum(mask_img)!=0: #tumor\n",
        "#         slide_img.save(\"train/tumor/%d.jpg\" % tumor_count)\n",
        "#         tumor_count += 1\n",
        "#         imgs1 += data_aug(kp_image.img_to_array(slide_img)/255)\n",
        "        \n",
        "#   imgs = np.concatenate((np.asarray(imgs0),np.asarray(imgs1)))\n",
        "#   labels = np.append(np.repeat(0.,len(imgs0)),np.repeat(1.,len(imgs1)))\n",
        "#   ind = [i for i in range(labels.shape[0])]\n",
        "#   np.random.shuffle(ind)\n",
        "  \n",
        "#   return imgs[ind], labels[ind]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rq4sZ04E0bx_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Version 2.0\n",
        "def data_preprocess(slide, tumor_mask, level, window_size=(299,299),\n",
        "                           center_size=(128,128),stride=128):\n",
        "  \n",
        "  factor = int(slide.level_downsamples[level])\n",
        "  tumor_count = 1\n",
        "  normal_count = 1\n",
        "  x_step = (window_size[0]-center_size[0])//2\n",
        "  y_step = (window_size[1]-center_size[1])//2\n",
        "  imgs0 = []\n",
        "  imgs1 = []\n",
        "  \n",
        "  for i in range(0, slide.level_dimensions[level][0]-window_size[0], stride):  \n",
        "    for j in range(0, slide.level_dimensions[level][1]-window_size[1], stride): \n",
        "      slide_img = read_slide(slide, i*factor, j*factor, level, window_size[0], window_size[1], as_float=False)\n",
        "      mask_img = read_slide(tumor_mask, (i+x_step)*factor, (j+y_step)*factor, level, center_size[0], center_size[1], as_float=False)\n",
        "      if np.sum(mask_img)==0:   #normal\n",
        "        if np.random.uniform(size=1)>0.75: #0.75 has to be tuned each time when we change the size!\n",
        "          imgs0.append(kp_image.img_to_array(slide_img)/255)  \n",
        "      elif np.sum(mask_img)!=0: #tumor\n",
        "        imgs1 += data_aug(kp_image.img_to_array(slide_img)/255)\n",
        "        \n",
        "  imgs = np.concatenate((np.asarray(imgs0),np.asarray(imgs1)))\n",
        "  labels = np.append(np.repeat(0.,len(imgs0)),np.repeat(1.,len(imgs1)))\n",
        "  ind = [i for i in range(labels.shape[0])]\n",
        "  np.random.shuffle(ind)\n",
        "  \n",
        "  return imgs[ind], labels[ind]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "io0P6kIBdGEZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "window_size=(80,80)\n",
        "center_size=(50,50)\n",
        "stride=50\n",
        "level=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cs0wlqBgFAyx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "patches, labels= data_preprocess(slide, tumor_mask, level=3, window_size=window_size,\n",
        "                           center_size=center_size,stride=stride)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rtojwj50m3yc",
        "colab_type": "code",
        "outputId": "3f704ee6-1f2d-42e5-d600-206c25ea6e46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "np.unique(labels,return_counts=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0., 1.]), array([4964, 3376]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "8QehlpGUNttn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 2: Train a Model"
      ]
    },
    {
      "metadata": {
        "id": "1cJRI1Y7PGMh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "e87aeab0-da3c-4407-83ed-c46a6ba4bc14"
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.applications.VGG16(input_shape=(299, 299, 3),include_top=False)\n",
        "model.trainable = False\n",
        "x = model.output\n",
        "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "predictions = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_baseline = tf.keras.models.Model(inputs = model.input, outputs = predictions)\n",
        "model_baseline.compile(loss =\"binary_crossentropy\",\n",
        "                       optimizer = tf.train.RMSPropOptimizer(learning_rate=0.0001),\n",
        "                       metrics=[\"accuracy\"])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v5xYVQkZZkWn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_baseline.fit(patches,labels,epochs=10,batch_size=32,validation_split=0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ig3rkDwv1eXl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_baseline.save_weights('baseline_80_50.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XVOvQcZzKYaZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # if running time died, please run this step after building model directly.\n",
        "# model_baseline.load_weights('baseline_80_50.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m2XBf7uBdEvw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 2.1 weighted loss"
      ]
    },
    {
      "metadata": {
        "id": "kJ2yp-oQdBAK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from functools import partial, update_wrapper\n",
        "\n",
        "def wrapped_partial(func, *args, **kwargs):\n",
        "\tpartial_func = partial(func, *args, **kwargs)\n",
        "\tupdate_wrapper(partial_func, func)\n",
        "\treturn partial_func\n",
        "\n",
        "def binary_crossentropy_weigted(y_true, y_pred, class_weights):\n",
        "\ty_pred = K.clip(y_pred, K.epsilon(), 1.0 - K.epsilon())\n",
        "\tloss = K.mean(class_weights*(-y_true * K.log(y_pred) - (1.0 - y_true) * K.log(1.0 - y_pred)),axis=-1)\n",
        "\treturn loss\n",
        "\n",
        "custom_loss = wrapped_partial(binary_crossentropy_weigted, class_weights=np.array([1.0, 2.0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lyJz2c8Bd7R0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 2.2 multi-scale"
      ]
    },
    {
      "metadata": {
        "id": "UdjPJK5Td69s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 847
        },
        "outputId": "90c755b7-8ad3-4101-8f11-1901cc056e1f"
      },
      "cell_type": "code",
      "source": [
        "### layers defination\n",
        "\n",
        "input_shape_high = (300, 300, 3)\n",
        "input_shape_low = (150, 150, 3)\n",
        "\n",
        "\n",
        "## scale 1\n",
        "# input4 = tf.keras.layers.Input(shape = input_shape_high)\n",
        "model4 = tf.keras.applications.VGG16(input_shape=input_shape_high,include_top=False)\n",
        "model4.trainable = False\n",
        "input4 = model4.output\n",
        "layer_level4 = tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape_high,\n",
        "                 padding='same')(input4)\n",
        "layer_level4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(layer_level4)\n",
        "layer_level4 = tf.keras.layers.Conv2D(64, kernel_size=(3, 3),\n",
        "                                      activation='relu',\n",
        "                                      padding='same')(layer_level4)\n",
        "predictions4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(layer_level4)\n",
        "# predictions4 = tf.keras.layers.Dense(1, activation=\"sigmoid\")(layer_level4)\n",
        "\n",
        "## scale 2\n",
        "# input5 = tf.keras.layers.Input(shape = input_shape_low)\n",
        "model5 = tf.keras.applications.VGG16(input_shape=input_shape_low,include_top=False)\n",
        "model5.trainable = False\n",
        "input5 = model5.output\n",
        "layer_level5 = tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation = 'relu',\n",
        "                 input_shape = input_shape_low,\n",
        "                 padding = 'same')(input5)\n",
        "layer_level5 = tf.keras.layers.MaxPooling2D(pool_size = (2, 2))(layer_level5)\n",
        "predictions5 = tf.keras.layers.Conv2D(64, kernel_size = (3, 3),\n",
        "                                      activation = 'relu',\n",
        "                                      padding = 'same')(layer_level5)\n",
        "# predictions5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(layer_level5)\n",
        "\n",
        "\n",
        "## multi-scale\n",
        "# added = tf.keras.layers.Add()([predictions4, predictions5])\n",
        "added = tf.keras.layers.concatenate([predictions4, predictions5])\n",
        "# merged = Dense(1024, activation='relu')(merged)\n",
        "# merged = Dense(num_classes, activation='softmax')(merged)\n",
        "\n",
        "combine_layer = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(added)\n",
        "# combine_layer = tf.keras.layers.Flatten()(combine_layer)\n",
        "combine_layer = tf.keras.layers.Dense(128, activation ='relu')(combine_layer)\n",
        "out = tf.keras.layers.Dense(1, activation='sigmoid')(combine_layer)\n",
        "\n",
        "combine_model = tf.keras.models.Model(inputs=[model4.input, model5.input], outputs=out)\n",
        "\n",
        "combine_model.compile(optimizer=tf.train.RMSPropOptimizer(learning_rate=0.001),\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-2263793996ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombine_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mcombine_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m combine_model.compile(optimizer=tf.train.RMSPropOptimizer(learning_rate=0.001),\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;31m# Create a cache for iterator get_next op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_get_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWeakKeyDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m         'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     79\u001b[0m       \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m       \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m       \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network(\n\u001b[0;32m--> 268\u001b[0;31m         self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1831\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m       raise ValueError('The name \"' + name + '\" is used ' +\n\u001b[0;32m-> 1833\u001b[0;31m                        \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' times in the model. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1834\u001b[0m                        'All layer names should be unique.')\n\u001b[1;32m   1835\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnetwork_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The name \"block1_conv1\" is used 2 times in the model. All layer names should be unique."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "B_dNnKnfN9gD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 3: Prediction for Trained Slide"
      ]
    },
    {
      "metadata": {
        "id": "2WTwD_8MfbyB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## convert labels to mask\n",
        "def label2mask(y_pred, mask_size, window_size=(150,150),center_size=(100,100),stride=100):\n",
        "  \n",
        "  mask_pred=np.zeros((mask_size[1],mask_size[0]))\n",
        "  count=0\n",
        "  x_grid=center_size[0]//2\n",
        "  y_grid=center_size[1]//2\n",
        "  for j in range(0,mask_size[0]-window_size[0],stride):    \n",
        "    for i in range(0,mask_size[1]-window_size[1],stride):  \n",
        "      x_pos=i+window_size[0]//2\n",
        "      y_pos=j+window_size[1]//2\n",
        "      if count >= len(y_pred):\n",
        "        count -= 1\n",
        "      mask_pred[(x_pos-x_grid):(x_pos+x_grid),(y_pos-y_grid):(y_pos+y_grid)]=y_pred[count]\n",
        "      count += 1\n",
        "  return(mask_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OI8ET1RhyoQl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Note: we should get all labels of slide rather than the center region here! \n",
        "# Otherwise, we would underestimate our evaluation.\n",
        "def get_test_pred(model, slide, level, window_size=(299,299),\n",
        "                     center_size=(128,128),stride=128):\n",
        "  \n",
        "  factor = int(slide.level_downsamples[level])\n",
        "  preds = []\n",
        "  for i in range(0, slide.level_dimensions[level][0]-window_size[0],stride):  \n",
        "    for j in range(0, slide.level_dimensions[level][1]-window_size[1],stride): \n",
        "      slide_img = read_slide(slide, i*factor, j*factor, level, window_size[0], window_size[1], as_float=False)\n",
        "      patches = kp_image.img_to_array(slide_img)/255\n",
        "      y_pred = model.predict(np.expand_dims(patches.astype('float32'),axis=0))\n",
        "      preds.append(y_pred)\n",
        "  \n",
        "  mask_pred = label2mask(np.asarray(preds), slide.level_dimensions[level], window_size = window_size, \n",
        "                         center_size=center_size, stride = stride)\n",
        "  return mask_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9L0QrIgEftuO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mask_pred = get_test_pred(model_baseline, slide, level, window_size=window_size,\n",
        "                          center_size=center_size,stride=stride)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s2YQqLV8KWU5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "slide_image = np.asarray(read_slide(slide, x=0, y=0, \n",
        "                         level=level, \n",
        "                         width=slide.level_dimensions[level][0], \n",
        "                         height=slide.level_dimensions[level][1]))\n",
        "mask_image = np.asarray(read_slide(tumor_mask, x=0, y=0, \n",
        "                        level=level, \n",
        "                        width=slide.level_dimensions[level][0], \n",
        "                        height=slide.level_dimensions[level][1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d8oywC7H24vc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plt.figure(figsize=(10,10), dpi=50)\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.subplot(2,2,1)\n",
        "plt.imshow(slide_image)\n",
        "plt.imshow(mask_image[:,:,0],cmap='jet', alpha=0.5)\n",
        "plt.grid(False)\n",
        "plt.subplot(2,2,2)\n",
        "plt.imshow(slide_image)\n",
        "plt.imshow(mask_pred, cmap='jet',alpha=0.5) # Red regions contains cancer.\n",
        "plt.grid(False)\n",
        "plt.subplot(2,2,3)\n",
        "plt.imshow(mask_image[:,:,0])\n",
        "plt.imshow(mask_pred, cmap='jet',alpha=0.5) # Red regions contains cancer.\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q4gCF8yyyZ38",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 4: Prediction for a New Slide"
      ]
    },
    {
      "metadata": {
        "id": "t4ALhWIbys__",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Download a test slide\n",
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "fname = 'tumor_078.tif'\n",
        "if not os.path.exists(fname): \n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  f_ = drive.CreateFile({'id': '1cAFgPCkGR0zH0gqCDo4yBnstNoZmjp3C'})\n",
        "  f_.GetContentFile(fname)\n",
        "  fname = 'tumor_078_mask.tif'\n",
        "  f_ = drive.CreateFile({'id': '1ZC2urznY3gRebUG3PN2BtYD1ZPZ7GPYq'})\n",
        "  f_.GetContentFile(fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V4Da20maykkd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "slide_test_path = 'tumor_078.tif'\n",
        "test_mask_path = 'tumor_078_mask.tif'\n",
        "slide_test = open_slide(slide_test_path)\n",
        "mask_test = open_slide(test_mask_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JAN2ROv-zO5E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mask_pred_test = get_test_pred(model_baseline, slide_test, level, window_size=window_size,\n",
        "                               center_size=center_size,stride=stride)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JZKJJ6lZzfLU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "slide_test_image = np.asarray(read_slide(slide_test, x=0, y=0, \n",
        "                              level=level, \n",
        "                              width=slide_test.level_dimensions[level][0], \n",
        "                              height=slide_test.level_dimensions[level][1]))\n",
        "mask_test_image = np.asarray(read_slide(mask_test, x=0, y=0, \n",
        "                             level=level, \n",
        "                             width=slide_test.level_dimensions[level][0], \n",
        "                             height=slide_test.level_dimensions[level][1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J3OOZ0i6zZM4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plt.figure(figsize=(10,10), dpi=50)\n",
        "plt.figure(figsize=(12,10))\n",
        "plt.subplot(2,2,1)\n",
        "plt.imshow(slide_test_image)\n",
        "plt.imshow(mask_test_image[:,:,0],cmap='jet', alpha=0.5)\n",
        "plt.grid(False)\n",
        "plt.subplot(2,2,2)\n",
        "plt.imshow(slide_test_image)\n",
        "plt.imshow(mask_pred_test, cmap='jet',alpha=0.5) # Red regions contains cancer.\n",
        "plt.grid(False)\n",
        "plt.subplot(2,2,3)\n",
        "plt.imshow(mask_test_image[:,:,0])\n",
        "plt.imshow(mask_pred_test, cmap='jet',alpha=0.5) # Red regions contains cancer.\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OhLnlTSsOMFn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 5: Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "Wpd0yDqKCD3d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "import sklearn\n",
        "\n",
        "fpr, tpr, thresholds = metrics.roc_curve(mask_test_image[:,:,0].reshape(-1).astype('float32'), \n",
        "                                         mask_pred_test.reshape(-1), pos_label=None)\n",
        "\n",
        "print('AUC:%s'%(metrics.auc(fpr, tpr)))\n",
        "\n",
        "plt.title('ROC curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.plot(fpr, tpr)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7OTmcRX5PfTv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "thres = thresholds[np.argmax(1-fpr+tpr)]\n",
        "mask_pred_test_labels = np.zeros(mask_pred_test.shape)\n",
        "mask_pred_test_labels[mask_pred_test > thres] = 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G7q2Ns5cPWRc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "mat = confusion_matrix(mask_test_image[:,:,0].reshape(-1).astype('uint8'), \n",
        "                       mask_pred_test_labels.reshape(-1).astype('uint8'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "01DkXjifraYv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j5heh1T5pU4s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "recall = mat[1][1]/(mat[1][1]+mat[1][0])   #tp/tp+fn\n",
        "precision = mat[1][1]/(mat[1][1]+mat[0][1])  #tp/tp+fp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OAR8jE4ojEnQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Recall:{}'.format(recall))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FlOsPbrxjIu2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Precision:{}'.format(precision))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}